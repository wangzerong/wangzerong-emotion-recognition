{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n",
      "to tensor done\n",
      "dataloader done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# import torchvision.datasets as dsets\n",
    "# import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 300\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomSizedCrop(224),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "#                          std  = [ 0.229, 0.224, 0.225 ]),\n",
    "#     ])\n",
    "\n",
    "\n",
    "\n",
    "# with open('./ck+.pkl', 'rb') as f:\n",
    "#      data = pickle.load(f)\n",
    "# print('load done')     \n",
    "\n",
    "# index = [i for i in range(927)]\n",
    "# random.shuffle(index)\n",
    "# trainindex = index[:835]\n",
    "# testindex = index[835:]\n",
    "\n",
    "# # dic = {'angry':0, 'disgust':1, 'fear':2, 'happy':3, 'neutral':4, 'sad':5, 'surprise':6}\n",
    "# dic = {'angry':0, 'disgusted':1, 'fearful':2, 'happy':3, 'sadness':4, 'surprised':5}\n",
    "# for i in range(len(data[1])):\n",
    "#     data[1][i] = dic[data[1][i]]\n",
    "# testlabel = np.array(data[1])[testindex]\n",
    "# trainlabel = np.array(data[1])[trainindex]\n",
    "# testdata = np.array(data[3])[testindex]\n",
    "# traindata = np.array(data[3])[trainindex]\n",
    "\n",
    "# trainData = TensorDataset(torch.Tensor(traindata), torch.LongTensor(trainlabel))\n",
    "# testData = TensorDataset(torch.Tensor(testdata), torch.LongTensor(testlabel))\n",
    "# print('to tensor done')\n",
    "\n",
    "# trainLoader = DataLoader(dataset=trainData, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# testLoader = DataLoader(dataset=testData, batch_size=1, shuffle=False)\n",
    "# print('dataloader done')\n",
    "\n",
    "with open('./raf_train.pkl', 'rb') as f:\n",
    "     train_data = pickle.load(f)\n",
    "print('load train done')\n",
    "\n",
    "# with open('./raf_test.pkl', 'rb') as f:\n",
    "#      test_data = pickle.load(f)\n",
    "# print('load test done')\n",
    "\n",
    "\n",
    "trainData = TensorDataset(torch.Tensor(train_data[2]), torch.LongTensor(train_data[0]))\n",
    "# testData = TensorDataset(torch.Tensor(test_data[2]), torch.LongTensor(test_data[0]))\n",
    "print('to tensor done')\n",
    "\n",
    "trainLoader = DataLoader(dataset=trainData, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# testLoader = DataLoader(dataset=testData, batch_size=1, shuffle=False)\n",
    "print('dataloader done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 tensor(1.7012, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 36 %\n",
      "epoch: 1 tensor(1.6629, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 48 %\n",
      "epoch: 2 tensor(1.8206, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 56 %\n",
      "epoch: 3 tensor(1.6654, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 60 %\n",
      "epoch: 4 tensor(2.1585, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 56 %\n",
      "epoch: 5 tensor(1.1676, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 48 %\n",
      "epoch: 6 tensor(1.9154, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 60 %\n",
      "epoch: 7 tensor(1.4353, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 60 %\n",
      "epoch: 8 tensor(1.6653, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 58 %\n",
      "epoch: 9 tensor(1.4153, device='cuda:0')\n",
      "Test Accuracy of the model on the train images: 62 %\n"
     ]
    }
   ],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 1-2 conv layer\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 1 Pooling layer\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "\n",
    "            # 2-1 conv layer\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 2-2 conv layer\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 2 Pooling lyaer\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "\n",
    "            # 3-1 conv layer\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 3-2 conv layer\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 3 Pooling layer\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "\n",
    "            # 4-1 conv layer\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 4-2 conv layer\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 4 Pooling layer\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            \n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "\n",
    "            # 5-1 conv layer\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 5-2 conv layer\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 5 Pooling layer\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            nn.AvgPool2d(kernel_size=6, stride=6))\n",
    "        \n",
    "\n",
    "        self.layer6 = nn.Sequential(\n",
    "\n",
    "            # 6 Fully connected layer\n",
    "            nn.Linear(512, 512),\n",
    "            # nn.Dropout(),\n",
    "            nn.ReLU())\n",
    "\n",
    "\n",
    "        self.layer7 = nn.Sequential(\n",
    "\n",
    "            # 7 Fully connected layer\n",
    "            nn.Linear(512*10, 1024),\n",
    "            # nn.Dropout(),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer8 = nn.Sequential(\n",
    "\n",
    "            # 8 output layer\n",
    "            nn.Linear(1024, 7),\n",
    "            nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape ==(-1,11,96,96,3)\n",
    "        out = []\n",
    "        for k in range(11):\n",
    "            #print(k)\n",
    "            f = x[:,k,:,:,:]\n",
    "            f = f.permute(0,3,1,2) \n",
    "            #（-1，3，96，96）\n",
    "            f = self.layer1(f)  \n",
    "            # (-1, 64, 48, 48)\n",
    "            f = self.layer2(f)  \n",
    "            # (-1, 128, 24, 24)\n",
    "            f = self.layer3(f)  \n",
    "            # (-1, 256, 12, 12)\n",
    "            f = self.layer4(f) \n",
    "            # （-1，512，6，6）\n",
    "            f = self.layer5(f) \n",
    "            # （-1，512，1，1）\n",
    "            f = f.view(f.size(0),-1)\n",
    "            # (-1, 512)\n",
    "            f = self.layer6(f)\n",
    "            # (-1, 512)\n",
    "            out.append(f)\n",
    "        out = torch.cat(out,axis=1) \n",
    "        #  (-1, 512*10)\n",
    "        out = self.layer7(out)\n",
    "        # (-1, 1024)\n",
    "        out = self.layer8(out)\n",
    "        # (-1, 7)\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "vgg16 = VGG16()\n",
    "vgg16.cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg16.parameters(), lr=LEARNING_RATE)\n",
    "# Train the model\n",
    "vgg16.train()\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "for epoch in range(EPOCH):\n",
    "    if epoch > 80:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 1e-5\n",
    "    if epoch > 180:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 1e-6\n",
    "            \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(trainLoader):\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        out = vgg16.forward(images)\n",
    "        #print(out.shape,labels.shape)\n",
    "        loss = cost(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "#     for i in range(400):\n",
    "#         index = np.random.randint(0, 12198, size=BATCH_SIZE)\n",
    "#         images = np.array(train_data[3]).reshape(-1, 10, 96, 96, 3)[index]\n",
    "#         images = Variable(torch.Tensor(images)).cuda()\n",
    "#         labels = np.array(train_data[1])[index]\n",
    "#         labels = Variable(torch.LongTensor(labels)).cuda()\n",
    "        \n",
    "#         out = vgg16.forward(images)\n",
    "#         # print(out.shape,labels.shape)\n",
    "#         loss = cost(out, labels)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         _, predicted = torch.max(out.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum()\n",
    "    \n",
    "    loss_list.append(loss.data)\n",
    "    acc_list.append(correct/total)\n",
    "    print('epoch: %d' % epoch, loss.data)\n",
    "    print('Test Accuracy of the model on the train images: %d %%' % (100 * correct / total))\n",
    "    if (epoch+1) % 10 == 0 :\n",
    "        torch.save(vgg16.state_dict(), './RAFDB/vgg13epoch{}.pkl'.format(epoch))\n",
    "        \n",
    "# Test the model\n",
    "# vgg16.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# for images, labels in testLoader:\n",
    "#     images = Variable(images).cuda()\n",
    "#     outputs = vgg16(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "# print('Test Accuracy of the model on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 72 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "vgg16.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in testLoader:\n",
    "    images = Variable(images).cuda()\n",
    "    outputs = vgg16(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VGG11/13/16/19 in Pytorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.fc1 = nn.Linear(32768, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.fc1(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "class CK(data.Dataset):\n",
    "    \"\"\"`CK+ Dataset.\n",
    "    Args:\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        there are 135,177,75,207,84,249,54 images in data\n",
    "        we choose 123,159,66,186,75,225,48 images for training\n",
    "        we choose 12,8,9,21,9,24,6 images for testing\n",
    "        the split are in order according to the fold number\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split='Training', fold = 1, transform=None):\n",
    "        self.transform = transform\n",
    "        self.split = split  # training set or test set\n",
    "        self.fold = fold # the k-fold cross validation\n",
    "        self.data = h5py.File('./data/CK_data.h5', 'r', driver='core')\n",
    "\n",
    "        number = len(self.data['data_label']) #981\n",
    "        sum_number = [0,135,312,387,594,678,927,981] # the sum of class number\n",
    "        test_number = [12,18,9,21,9,24,6] # the number of each class\n",
    "\n",
    "        test_index = []\n",
    "        train_index = []\n",
    "\n",
    "        for j in xrange(len(test_number)):\n",
    "            for k in xrange(test_number[j]):\n",
    "                if self.fold != 10: #the last fold start from the last element\n",
    "                    test_index.append(sum_number[j]+(self.fold-1)*test_number[j]+k)\n",
    "                else:\n",
    "                    test_index.append(sum_number[j+1]-1-k)\n",
    "\n",
    "        for i in xrange(number):\n",
    "            if i not in test_index:\n",
    "                train_index.append(i)\n",
    "\n",
    "        print(len(train_index),len(test_index))\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        if self.split == 'Training':\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            for ind in xrange(len(train_index)):\n",
    "                self.train_data.append(self.data['data_pixel'][train_index[ind]])\n",
    "                self.train_labels.append(self.data['data_label'][train_index[ind]])\n",
    "\n",
    "        elif self.split == 'Testing':\n",
    "            self.test_data = []\n",
    "            self.test_labels = []\n",
    "            for ind in xrange(len(test_index)):\n",
    "                self.test_data.append(self.data['data_pixel'][test_index[ind]])\n",
    "                self.test_labels.append(self.data['data_label'][test_index[ind]])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.split == 'Training':\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        elif self.split == 'Testing':\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = img[:, :, np.newaxis]\n",
    "        img = np.concatenate((img, img, img), axis=2)\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.split == 'Training':\n",
    "            return len(self.train_data)\n",
    "        elif self.split == 'Testing':\n",
    "            return len(self.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 crop for data enhancement\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import utils\n",
    "from CK import CK\n",
    "from torch.autograd import Variable\n",
    "from models import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch CK+ CNN Training')\n",
    "parser.add_argument('--model', type=str, default='VGG19', help='CNN architecture')\n",
    "parser.add_argument('--dataset', type=str, default='CK+', help='dataset')\n",
    "parser.add_argument('--fold', default=1, type=int, help='k fold number')\n",
    "parser.add_argument('--bs', default=128, type=int, help='batch_size')\n",
    "parser.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "opt = parser.parse_args()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "best_Test_acc = 0  # best PrivateTest accuracy\n",
    "best_Test_acc_epoch = 0\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "learning_rate_decay_start = 20  # 50\n",
    "learning_rate_decay_every = 1 # 5\n",
    "learning_rate_decay_rate = 0.8 # 0.9\n",
    "\n",
    "total_epoch = 60\n",
    "\n",
    "path = os.path.join(opt.dataset + '_' + opt.model, str(opt.fold))\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = CK(split = 'Training', fold = opt.fold, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=opt.bs, shuffle=True, num_workers=1)\n",
    "testset = CK(split = 'Testing', fold = opt.fold, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False, num_workers=1)\n",
    "\n",
    "# Model\n",
    "if opt.model == 'VGG19':\n",
    "    net = VGG('VGG19')\n",
    "elif opt.model == 'Resnet18':\n",
    "    net = ResNet18()\n",
    "\n",
    "if opt.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir(path), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(os.path.join(path,'Test_model.t7'))\n",
    "    \n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_Test_acc = checkpoint['best_Test_acc']\n",
    "    best_Test_acc_epoch = checkpoint['best_Test_acc_epoch']\n",
    "    start_epoch = best_Test_acc_epoch + 1\n",
    "else:\n",
    "    print('==> Building model..')\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=opt.lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    global Train_acc\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if epoch > learning_rate_decay_start and learning_rate_decay_start >= 0:\n",
    "        frac = (epoch - learning_rate_decay_start) // learning_rate_decay_every\n",
    "        decay_factor = learning_rate_decay_rate ** frac\n",
    "        current_lr = opt.lr * decay_factor\n",
    "        utils.set_lr(optimizer, current_lr)  # set the decayed rate\n",
    "    else:\n",
    "        current_lr = opt.lr\n",
    "    print('learning_rate: %s' % str(current_lr))\n",
    "\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        utils.clip_gradient(optimizer, 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        utils.progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    Train_acc = 100.*correct/total\n",
    "\n",
    "def test(epoch):\n",
    "    global Test_acc\n",
    "    global best_Test_acc\n",
    "    global best_Test_acc_epoch\n",
    "    net.eval()\n",
    "    PrivateTest_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        bs, ncrops, c, h, w = np.shape(inputs)\n",
    "        inputs = inputs.view(-1, c, h, w)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        outputs_avg = outputs.view(bs, ncrops, -1).mean(1)  # avg over crops\n",
    "\n",
    "        loss = criterion(outputs_avg, targets)\n",
    "        PrivateTest_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs_avg.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        utils.progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (PrivateTest_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "    # Save checkpoint.\n",
    "    Test_acc = 100.*correct/total\n",
    "\n",
    "    if Test_acc > best_Test_acc:\n",
    "        print('Saving..')\n",
    "        print(\"best_Test_acc: %0.3f\" % Test_acc)\n",
    "        state = {'net': net.state_dict() if use_cuda else net,\n",
    "            'best_Test_acc': Test_acc,\n",
    "            'best_Test_acc_epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(opt.dataset + '_' + opt.model):\n",
    "            os.mkdir(opt.dataset + '_' + opt.model)\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "        torch.save(state, os.path.join(path, 'Test_model.t7'))\n",
    "        best_Test_acc = Test_acc\n",
    "        best_Test_acc_epoch = epoch\n",
    "\n",
    "for epoch in range(start_epoch, total_epoch):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "print(\"best_Test_acc: %0.3f\" % best_Test_acc)\n",
    "print(\"best_Test_acc_epoch: %d\" % best_Test_acc_epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1gpu_40Gmemory_8cpu",
   "language": "python3",
   "name": "1gpu_40gmemory_8cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
