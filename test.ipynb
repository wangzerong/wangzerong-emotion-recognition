{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load test done\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# import torchvision.datasets as dsets\n",
    "# import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "with open('./raf_test.pkl', 'rb') as f:\n",
    "     test_data = pickle.load(f)\n",
    "print('load test done')\n",
    "\n",
    "regions = torch.Tensor(test_data[2])# (12198,11,96,96,3)\n",
    "re = regions[:, :10]\n",
    "print('1')\n",
    "points = torch.Tensor(test_data[1])# (12198,10,2)\n",
    "print('2')\n",
    "labels = torch.LongTensor(test_data[0])#(12198)\n",
    "print('3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.module import Module\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,in_features, out_features, bias=True): #(shape256, 256)\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        # (A*X*W)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # inputs (b,10,256)\n",
    "        # ajd (b,10,10)\n",
    "        x = x.view(-1,256)\n",
    "        support = torch.mm(x, self.weight) #(b*10,256)\n",
    "        support = support.view(-1,10,support.size(1))\n",
    "        output = torch.bmm(adj, support) #(b,10,10)*(b,10.256)  (b,10,256)\n",
    "        if self.bias is not None:\n",
    "            #print(output.shape,self.bias.shape)\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self,nfeat):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(nfeat, 256)\n",
    "        self.gc2 = GraphConvolution(256, 256)\n",
    "        self.fc1 = nn.Linear(256*10, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 7)  \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # x = self.dropout(F.relu(self.gc1(x, adj)))\n",
    "        # x = self.gc2(x, adj) #(-1,10,256)\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = self.dropout(x.view(x.size(0),-1))      \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "def get_batch_graph(inp,k=8):\n",
    "    assert len(inp.shape) == 3\n",
    "    x=inp\n",
    "    norm1 = torch.sum(x**2,axis=2).reshape((x.shape[0],-1,1))\n",
    "    norm2 = torch.sum(x**2,axis=2).reshape((x.shape[0],1,-1))\n",
    "    dist = torch.bmm(x,x.permute(0,2,1))*(-2)+norm1+norm2\n",
    "    sigma2 = torch.mean(dist,axis=2).reshape(-1,10,1)\n",
    "    dist = torch.exp(-dist/sigma2)\n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 1-2 conv layer\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 1 Pooling layer\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "\n",
    "            # 2-1 conv layer\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 2-2 conv layer\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 2 Pooling lyaer\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "\n",
    "            # 3-1 conv layer\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 3-2 conv layer\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 3 Pooling layer\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            nn.AvgPool2d(kernel_size=24, stride=24))\n",
    "        \n",
    "\n",
    "        self.layer6 = nn.Sequential(\n",
    "\n",
    "            # 6 Fully connected layer\n",
    "            nn.Linear(256, 256),\n",
    "            # nn.Dropout(),\n",
    "            nn.ReLU())\n",
    "\n",
    "\n",
    "        self.layer7 = nn.Sequential(\n",
    "\n",
    "            # 7 Fully connected layer\n",
    "            nn.Linear(256*10, 1024),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer8 = nn.Sequential(\n",
    "\n",
    "            # 8 output layer\n",
    "            nn.Linear(1024, 7),\n",
    "            nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape ==(-1,10,96,96,3)\n",
    "        out = []\n",
    "        for k in range(10):\n",
    "            #print(k)\n",
    "            f = x[:,k,:,:,:]\n",
    "            f = f.permute(0,3,1,2) \n",
    "            #（-1，3，96，96）\n",
    "            f = self.layer1(f)  \n",
    "            # (-1, 64, 48, 48)\n",
    "            f = self.layer2(f)  \n",
    "            # (-1, 128, 24, 24)\n",
    "            f = self.layer3(f)  \n",
    "            # (-1, 256, 1, 1)\n",
    "            f = f.view(f.size(0),-1)\n",
    "            # (-1, 256)\n",
    "            # f = self.layer6(f)\n",
    "            # (-1, 256)\n",
    "            out.append(f)\n",
    "        out = torch.cat(out,axis=1) \n",
    "        #  (-1, 256*10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor(1839, device='cuda:0') 3068\n",
      "Test Accuracy of the model on the test images: 59.000000 %\n",
      "19\n",
      "tensor(1846, device='cuda:0') 3068\n",
      "Test Accuracy of the model on the test images: 60.000000 %\n",
      "29\n",
      "tensor(2004, device='cuda:0') 3068\n",
      "Test Accuracy of the model on the test images: 65.000000 %\n",
      "39\n",
      "tensor(2006, device='cuda:0') 3068\n",
      "Test Accuracy of the model on the test images: 65.000000 %\n",
      "49\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dd151e133bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#(16, 256*10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-85831c23d7fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# (-1, 128, 24, 24)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;31m# (-1, 256, 1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "adjs = get_batch_graph(points)\n",
    "BATCH_SIZE = 4\n",
    "index = [i for i in range(3068)]\n",
    "vgg16 = VGG16()\n",
    "vgg16.cuda()\n",
    "checkpoint = torch.load('./RAFDB/vgg_dropout_epoch349.pkl')\n",
    "vgg16.load_state_dict(checkpoint['net'])\n",
    "vgg16.eval()\n",
    "gcn =  GCN(256)\n",
    "for i in range(9, 109, 10):\n",
    "    print(i)\n",
    "    path = './RAFDB/gcnfea' + str(i) +'.pkl'\n",
    "    check = torch.load(path)\n",
    "    # from collections import OrderedDict\n",
    "    # new_check = OrderedDict()\n",
    "    # for k, v in checkpoint.items():\n",
    "    #     if 'module' not in k:\n",
    "    #         k = 'module.'+k\n",
    "    #     else:\n",
    "    #         k = k.replace('features.module.', 'module.features.')\n",
    "    #     new_check[k]=v\n",
    "\n",
    "    gcn.load_state_dict(check['net'])\n",
    "    gcn.cuda()\n",
    "\n",
    "    # Test the model\n",
    "    gcn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(767):\n",
    "        tmp = index[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        img = Variable(re[tmp]).cuda()\n",
    "        outputs = vgg16(img)  #(16, 256*10)\n",
    "        outputs = outputs.reshape(-1, 10, 256)\n",
    "        label = Variable(labels[tmp]).cuda()\n",
    "        adj = adjs[tmp].cuda()\n",
    "        out = gcn.forward(outputs,adj)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum()\n",
    "    print(correct, total)\n",
    "    print('Test Accuracy of the model on the test images: %f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load test done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from IPython import embed\n",
    "import torch.nn.functional as F\n",
    "\n",
    "with open('./raf_test_96.pkl', 'rb') as f:\n",
    "     test_data = pickle.load(f)\n",
    "print('load test done')\n",
    "\n",
    "# testData = TensorDataset((torch.Tensor(test_data[2]))[:, :10], torch.LongTensor(test_data[0]))\n",
    "# # testData = TensorDataset(torch.Tensor(test_data[2]), torch.LongTensor(test_data[0]))\n",
    "# print('to tensor done')\n",
    "\n",
    "# testLoader = DataLoader(dataset=testData, batch_size=1, shuffle=False)\n",
    "# print('dataloader done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = TensorDataset(torch.Tensor(test_data[2]), torch.LongTensor(test_data[0]))\n",
    "print('to tensor done')\n",
    "\n",
    "testLoader = DataLoader(dataset=testData, batch_size=2, shuffle=False)\n",
    "print('dataloader done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VGG16:\n\tUnexpected key(s) in state_dict: \"features.3.weight\", \"features.3.bias\", \"features.6.weight\", \"features.6.bias\", \"features.8.weight\", \"features.8.bias\", \"features.10.weight\", \"features.10.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c0c37309ac47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# remove `module.`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mnew_state_dictBA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state_dictBA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VGG16:\n\tUnexpected key(s) in state_dict: \"features.3.weight\", \"features.3.bias\", \"features.6.weight\", \"features.6.bias\", \"features.8.weight\", \"features.8.bias\", \"features.10.weight\", \"features.10.bias\". "
     ]
    }
   ],
   "source": [
    "class VGG16(nn.Module):  # vgg-11\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(33, 64, kernel_size=3, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512 * 3 * 3, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 7),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = []\n",
    "        for k in range(11):\n",
    "            f = x[:,k,:,:,:]\n",
    "            f = f.permute(0,3,1,2) \n",
    "            inp.append(f)\n",
    "        inp = torch.cat(inp, axis=1)\n",
    "        out = self.features(inp)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "vgg16 = VGG16()\n",
    "\n",
    "path = './RAFDB/vgg11allepoch189.pkl'\n",
    "from collections import OrderedDict\n",
    "# def myOwnLoad(model, check):\n",
    "#     modelState = model.state_dict()\n",
    "#     tempState = OrderedDict()\n",
    "#     for i in range(len(check.keys())):\n",
    "#         # print modelState.keys()[i], check.keys()[i]\n",
    "#         tempState[modelState.keys()[i]] = check[check.keys()[i]]\n",
    "\n",
    "#     model.load_state_dict(tempState)\n",
    "#     return model\n",
    "state_dictBA = torch.load(path)['net']\n",
    "# create new OrderedDict that does not contain `module.`\n",
    "new_state_dictBA = OrderedDict()\n",
    "for k, v in state_dictBA.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dictBA[name] = v\n",
    "vgg16.load_state_dict(new_state_dictBA)\n",
    "\n",
    "\n",
    "# checkpoint = torch.load(path)\n",
    "# vgg16 = myOwnLoad(vgg16, checkpoint['net'])\n",
    "# vgg16.load_state_dict(checkpoint['net'])\n",
    "vgg16.cuda()\n",
    "\n",
    "# Test the model\n",
    "vgg16.eval()\n",
    "\n",
    "images = Variable(img).cuda()\n",
    "outputs = vgg16(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 6.0277],\n",
       "        [0.0000, 0.0000]], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][10,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fba24e05860>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "f = outputs[0][10].cpu().detach().numpy()\n",
    "f = f.reshape(2,2,1)\n",
    "a = np.concatenate((f,f,f), axis=2)\n",
    "plt.imshow(a) #（R,G,B）\n",
    "# plt.imshow(f,cmap='gray') #（R,G,B）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fba24fc5da0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a) #（R,G,B）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
